{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b969150b",
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "cross_val_score() 함수\n",
    " fold set 추출, 학습/예측, 평가를\n",
    " 한 번에 수행하는 점수\n",
    " \n",
    "GridSearchCV\n",
    " 교차 검증과 최적 하이퍼 파라미터 튜닝을 한번에 함\n",
    "                   ㄴ Classifier(분류) / Regressor(화가)알고리즘에서 사용함\n",
    "  하이퍼 파라미터 순차적으로 입력하면서\n",
    "  최적의 파라미터 도출\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7fec9065",
   "metadata": {},
   "source": [
    "#### crossvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6bff429d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "교차 검증별 정확도 : [0.98 0.94 0.98]\n",
      "평균 검증 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.model_selection import cross_val_score, cross_validate\n",
    "from sklearn.datasets import load_iris\n",
    "import numpy as np\n",
    "\n",
    "iris_data = load_iris()\n",
    "dt_clf = DecisionTreeClassifier(random_state=156)\n",
    "\n",
    "data = iris_data.data\n",
    "label = iris_data.target\n",
    "\n",
    "'''\n",
    "scoring= \"accuracy\" <-- 성능 지표를 정확도로함\n",
    "cv=3               <-- 교차검증 세트를 3개로 함\n",
    "'''\n",
    "#교차 검증별 정확도를 리스트로 반환함\n",
    "score = cross_val_score(dt_clf, data, label, scoring=\"accuracy\",cv=3)\n",
    "\n",
    "print(f\"교차 검증별 정확도 : {np.round(score,4)}\")\n",
    "print(f\"평균 검증 정확도 : {np.round(np.mean(score),4)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12c2b029",
   "metadata": {},
   "source": [
    "### GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "3ff12197",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# 데이터 세트 로딩하고 학습데이터와 테스트데이터 분리하기\n",
    "iris = load_iris()\n",
    "X_train, X_test, y_train, y_test = \\\n",
    "  train_test_split(iris.data, iris.target, test_size=0.2, random_state=121)\n",
    "dt_clf = DecisionTreeClassifier()\n",
    "\n",
    "'''\n",
    "parameter 들을 dictionary로 설정하기\n",
    " ㄴ GridSearchCV 수행할 때 지정한 parameter 값들로 반복하면서 수행하면서\n",
    "    최적의 parameter 값을 찾음\n",
    "max_depth, min_samples_split : hyper parameter 이름\n",
    "[1,2,3], [2,3] : 순차적으로 수행할 때의 hyper parameter 값들\n",
    "'''\n",
    "# r param_grid\n",
    "parameters = {\"max_depth\":[1,2,3], \"min_samples_split\":[2,3]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "52311094",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>params</th>\n",
       "      <th>mean_test_score</th>\n",
       "      <th>rank_test_score</th>\n",
       "      <th>split0_test_score</th>\n",
       "      <th>split1_test_score</th>\n",
       "      <th>split2_test_score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 2}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{'max_depth': 1, 'min_samples_split': 3}</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>5</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.7</td>\n",
       "      <td>0.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 2}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{'max_depth': 2, 'min_samples_split': 3}</td>\n",
       "      <td>0.958333</td>\n",
       "      <td>3</td>\n",
       "      <td>0.925</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 2}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>{'max_depth': 3, 'min_samples_split': 3}</td>\n",
       "      <td>0.975000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.975</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     params  mean_test_score  rank_test_score  \\\n",
       "0  {'max_depth': 1, 'min_samples_split': 2}         0.700000                5   \n",
       "1  {'max_depth': 1, 'min_samples_split': 3}         0.700000                5   \n",
       "2  {'max_depth': 2, 'min_samples_split': 2}         0.958333                3   \n",
       "3  {'max_depth': 2, 'min_samples_split': 3}         0.958333                3   \n",
       "4  {'max_depth': 3, 'min_samples_split': 2}         0.975000                1   \n",
       "5  {'max_depth': 3, 'min_samples_split': 3}         0.975000                1   \n",
       "\n",
       "   split0_test_score  split1_test_score  split2_test_score  \n",
       "0              0.700                0.7               0.70  \n",
       "1              0.700                0.7               0.70  \n",
       "2              0.925                1.0               0.95  \n",
       "3              0.925                1.0               0.95  \n",
       "4              0.975                1.0               0.95  \n",
       "5              0.975                1.0               0.95  "
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "'''\n",
    "cv=3 : hyper parameter 들을 3개 train/ test set fold 로 나눔\n",
    "refit = True (default) - True 인 경우 가장 좋은 parameter 설정으로 재학습시킴\n",
    "GridSearchCV 생성자의 주요 parameter\n",
    "estimator 모델 (classification, regression)\n",
    "param_grid : {사용되는 parameter 명 : 값}, <-- dictionary 로 설정함\n",
    "cv : 교차 검증할때 분할하는 학습/테스트 세트의 개수\n",
    "'''\n",
    "grid_dt_clf = GridSearchCV(dt_clf, param_grid=parameters, cv=3, refit=True, return_train_score=True)\n",
    "\n",
    "# iris train data 로 paramt_grid값들로 순차적으로 학습/평가 수행하기\n",
    "grid_dt_clf.fit(X_train, y_train)\n",
    "\n",
    "'''\n",
    "# GridSearchCV 학습 결과는 cv_results_ 라는 dictionary에 저장도미\n",
    "이것을 DataFrame으로 변환해서 사용함\n",
    "'''\n",
    "scores_df = pd.DataFrame(grid_dt_clf.cv_results_)\n",
    "scores_df[[\"params\",\"mean_test_score\",\"rank_test_score\",\n",
    "          \"split0_test_score\", \"split1_test_score\", \"split2_test_score\"]\n",
    "         ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7d856360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_dt_clf.cv_results_ :\n",
      "{'mean_fit_time': array([0.00066519, 0.0006663 , 0.00101002, 0.00033267, 0.00099182,\n",
      "       0.00099715]), 'std_fit_time': array([4.70358870e-04, 4.71151362e-04, 1.46743144e-05, 4.70471221e-04,\n",
      "       6.57562879e-06, 4.49566384e-07]), 'mean_score_time': array([0.0006698 , 0.00099627, 0.00065343, 0.00066495, 0.00033283,\n",
      "       0.00033259]), 'std_score_time': array([4.73661751e-04, 2.59232623e-06, 4.62272469e-04, 4.70190252e-04,\n",
      "       4.70696004e-04, 4.70358829e-04]), 'param_max_depth': masked_array(data=[1, 1, 2, 2, 3, 3],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'param_min_samples_split': masked_array(data=[2, 3, 2, 3, 2, 3],\n",
      "             mask=[False, False, False, False, False, False],\n",
      "       fill_value='?',\n",
      "            dtype=object), 'params': [{'max_depth': 1, 'min_samples_split': 2}, {'max_depth': 1, 'min_samples_split': 3}, {'max_depth': 2, 'min_samples_split': 2}, {'max_depth': 2, 'min_samples_split': 3}, {'max_depth': 3, 'min_samples_split': 2}, {'max_depth': 3, 'min_samples_split': 3}], 'split0_test_score': array([0.7  , 0.7  , 0.925, 0.925, 0.975, 0.975]), 'split1_test_score': array([0.7, 0.7, 1. , 1. , 1. , 1. ]), 'split2_test_score': array([0.7 , 0.7 , 0.95, 0.95, 0.95, 0.95]), 'mean_test_score': array([0.7       , 0.7       , 0.95833333, 0.95833333, 0.975     ,\n",
      "       0.975     ]), 'std_test_score': array([1.11022302e-16, 1.11022302e-16, 3.11804782e-02, 3.11804782e-02,\n",
      "       2.04124145e-02, 2.04124145e-02]), 'rank_test_score': array([5, 5, 3, 3, 1, 1]), 'split0_train_score': array([0.7   , 0.7   , 0.975 , 0.975 , 0.9875, 0.9875]), 'split1_train_score': array([0.7   , 0.7   , 0.9375, 0.9375, 0.9625, 0.9625]), 'split2_train_score': array([0.7   , 0.7   , 0.9625, 0.9625, 0.9875, 0.9875]), 'mean_train_score': array([0.7       , 0.7       , 0.95833333, 0.95833333, 0.97916667,\n",
      "       0.97916667]), 'std_train_score': array([1.11022302e-16, 1.11022302e-16, 1.55902391e-02, 1.55902391e-02,\n",
      "       1.17851130e-02, 1.17851130e-02])}\n"
     ]
    }
   ],
   "source": [
    "print(\"grid_dt_clf.cv_results_ :\\n\",grid_dt_clf.cv_results_,sep=\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cac1a6b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "grid_dt_clf.cv 최적파라미터 :\n",
      " {'max_depth': 3, 'min_samples_split': 2}\n",
      "gridsearch 최고정확도 :,0.975000\n"
     ]
    }
   ],
   "source": [
    "print(f\"grid_dt_clf.cv 최적파라미터 :\\n\",grid_dt_clf.best_params_)\n",
    "print(f\"gridsearch 최고정확도 :,{grid_dt_clf.best_score_:4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "6aaee131",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 테스트 데이터 세트의 정확도 구하기 ---\n",
      "테스트 데이터 세트의 정확도 : 0.9667\n"
     ]
    }
   ],
   "source": [
    "print(\"--- 테스트 데이터 세트의 정확도 구하기 ---\")\n",
    "'''\n",
    "refit = True 로 설정된 GridSearchCV 객체의 fit() 메소드가 호출된 후,\n",
    "(학습이 완료된) Estimator(모델)를 내포하고 있으므로\n",
    "predict()를 호출해서 예측도 수행할 수 있음\n",
    "'''\n",
    "pred = grid_dt_clf.predict(X_test)\n",
    "print(f\"테스트 데이터 세트의 정확도 : {accuracy_score(y_test,pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "b7acfad1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "테스트 데이터 세트의 정확도 :0.9667\n"
     ]
    }
   ],
   "source": [
    "# GirdSearchCV 의 refit 으로 이미 학습된 estimator 를 반환함 : best_estimator 속성\n",
    "estimator = grid_dt_clf.best_estimator_\n",
    "'''\n",
    "GridSearchCV의 best_estimator_는 이미 최적 hyper parameter로 학습된 상태임\n",
    "이미 최적 hyper parameter 로 학습된 상태임\n",
    "'''\n",
    "pred = estimator.predict(X_test)\n",
    "print(f\"테스트 데이터 세트의 정확도 :{accuracy_score(y_test,pred):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34ecfa37",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcefd94",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16aa457c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b763780",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecfb4836",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9867b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
